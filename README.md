![IMG_0719](https://user-images.githubusercontent.com/16622605/151033781-299a607c-4000-47ac-89de-97c09490417d.JPG)
![IMG_0720](https://user-images.githubusercontent.com/16622605/151033790-c610610b-68f3-4d07-8a57-fb2bb8657ca4.JPG)
# Wilson
Here's Wilson, the lockdown friend.
Wilson can show hardcoded emotions with his OLED display "face" and voice and can be upgraded with Bluetooth actions.

His different faces are made in Affinity Designer (the Wilson.afdesign contains his actual faces et can be modified to add new ones) and are exported as BMPs (with low quality and colors) in the "Images" folder.
You must copy his faces and voices ("sounds" folder) on a MicroSD card (which goes on the OLED screen).
His voices are made using Audacity.
You can create new voices using the audacity macros included.
The idea was to have different voices for each action (to give him more life) so for each expressions, he will randomly choice a file contained in the folder of the expression.

Except for "Coucou" (which is a familiar way to say hello in french) the goal is to use as few words as possible and use mostly emotions from the face and the voice to make him "talk".

There are 2 buttons to trigger expressions but you can also use the Adafruits's Bluefruit Connect App to trigger those expressions via the bluetooth controller.

I'll make a proper readme one day because i realize this text isn't that clear.
